# Deep Learning-Based Digital Watermarking System

A comprehensive, production-ready implementation of image-in-image steganography using advanced Convolutional Autoencoders. This project provides multiple model variants, optimization techniques, and deployment options for digital watermarking applications.

## ğŸŒŸ Project Overview

This advanced implementation uses state-of-the-art deep learning techniques to perform robust image-in-image steganography:

- **ğŸ”§ Encoder Network**: Embeds secret images into cover images with minimal visual distortion
- **ğŸ” Decoder Network**: Extracts hidden secret images from stego images with high fidelity
- **ğŸ¯ Advanced Training**: Multi-objective optimization with perceptual loss functions
- **ğŸš€ Multiple Deployment Options**: From research prototypes to production web applications

## âœ¨ Key Features

### Core Capabilities
- **ğŸ—ï¸ Multiple Model Architectures**: Lightweight, standard, high-capacity, and robust variants
- **ğŸ”¬ Advanced Loss Functions**: MSE, SSIM, perceptual, and adversarial losses
- **ğŸ“Š Comprehensive Evaluation**: Robustness testing against common attacks (JPEG, noise, blur, etc.)
- **âš¡ Performance Optimization**: Mixed precision training, gradient clipping, advanced schedulers
- **ğŸ­ Interactive Demo**: Real-time demonstration with synthetic and custom images

### User Interfaces
- **ğŸŒ Web Application**: Beautiful, responsive web interface for easy usage
- **ğŸ“± RESTful API**: Programmatic access for integration with other systems
- **ğŸ–¥ï¸ Command Line Tools**: Comprehensive CLI for batch processing and automation
- **ğŸ“Š Visualization Suite**: Advanced plotting and analysis tools

### Deployment & Production
- **ğŸ”„ Batch Processing**: Handle multiple images with parallel processing
- **ğŸ“ˆ Model Monitoring**: Training metrics, validation curves, and performance tracking
- **ğŸ¨ Custom Datasets**: Support for any image dataset with flexible preprocessing
- **ğŸ”’ Robustness Testing**: Evaluation against compression, noise, geometric attacks

## Architecture

### Model Components

1. **Encoder Network**:
   - Input: Cover image (3 channels) + Secret image (3 channels) = 6 channels
   - Output: Stego image (3 channels)
   - Architecture: Convolutional layers with skip connections

2. **Decoder Network**:
   - Input: Stego image (3 channels)
   - Output: Recovered secret image (3 channels)
   - Architecture: Convolutional layers with skip connections

3. **Loss Functions**:
   - Cover Loss: MSE between cover and stego images
   - Secret Loss: MSE between original and recovered secret images
   - SSIM Loss: Structural similarity for better visual quality

## ğŸš€ Quick Start

### Automated Setup
```bash
# Run the automated setup script
python setup.py
```

### Manual Installation

#### Prerequisites
- Python 3.8+ (3.9+ recommended)
- PyTorch 2.0+
- CUDA 11.0+ (optional, for GPU acceleration)
- 8GB+ RAM (16GB+ recommended for training)

#### Step-by-Step Setup

1. **Clone and Navigate**:
   ```bash
   git clone <repository-url>
   cd DigitalWatermarking
   ```

2. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run Setup**:
   ```bash
   python setup.py  # Creates directories and configuration files
   ```

4. **Verify Installation**:
   ```bash
   python demo.py --mode inference --epochs 5
   ```

### ğŸ­ Instant Demo
```bash
# Quick demonstration with synthetic images
python demo.py --mode both --epochs 10 --image_size 64

# Web interface (open http://127.0.0.1:5000)
python web_app.py
```

## ğŸ“š Usage Guide

### ğŸ¯ 1. Training Models

#### Basic Training (CIFAR-10)
```bash
# Standard training
python train.py --epochs 50 --batch_size 32 --use_cifar --device cuda

# Advanced optimization
python optimization.py --epochs 100 --mixed_precision --config config.json
```

#### Custom Dataset Training
```bash
python train.py --epochs 50 --batch_size 16 \
  --custom_image_dir /path/to/images --device cuda
```

#### Model Variants
```bash
# Lightweight model for mobile deployment
python -c "
from model_variants import get_model_variant
model = get_model_variant('lightweight')
print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')
"

# High-capacity model for complex images
python -c "
from model_variants import get_model_variant  
model = get_model_variant('high_capacity')
print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')
"
```

### ğŸ” 2. Inference & Testing

#### Single Image Processing
```bash
python inference.py \
    --checkpoint checkpoints/best_model.pth \
    --cover_image cover.jpg \
    --secret_image secret.jpg \
    --output_dir results \
    --visualize
```

#### Batch Processing
```bash
# Embed multiple secrets
python batch_process.py --mode embed \
  --checkpoint checkpoints/best_model.pth \
  --cover_dir covers/ --secret_dir secrets/ \
  --output_dir batch_results/ --max_workers 4

# Extract from stego images
python batch_process.py --mode extract \
  --checkpoint checkpoints/best_model.pth \
  --stego_dir stegos/ --output_dir extracted/
```

### ğŸŒ 3. Web Interface

#### Launch Web App
```bash
# Basic launch
python web_app.py

# Custom configuration
python web_app.py --host 0.0.0.0 --port 8080 \
  --checkpoint checkpoints/best_model.pth --device cuda
```

#### Web Features
- **ğŸ“¤ Upload Interface**: Drag-and-drop image upload
- **âš™ï¸ Real-time Processing**: Instant steganography results
- **ğŸ“Š Quality Metrics**: PSNR and SSIM calculations
- **ğŸ’¾ Download Results**: High-quality output images
- **ğŸ“± Responsive Design**: Works on desktop and mobile

### ğŸ“Š 4. Evaluation & Analysis

#### Comprehensive Evaluation
```bash
python evaluate.py --checkpoint checkpoints/best_model.pth \
  --test_data cifar --num_samples 1000 --output_dir evaluation/
```

#### Robustness Testing
```bash
# Test against various attacks
python evaluate.py --checkpoint checkpoints/best_model.pth \
  --test_data cifar --num_samples 500 \
  --output_dir robustness_test/
```

#### Model Comparison
```bash
# Compare different model variants
python -c "
from model_variants import compare_model_sizes
compare_model_sizes()
"
```

## ğŸ“ Project Structure

```
DigitalWatermarking/
â”œâ”€â”€ ğŸ—ï¸ Core Models
â”‚   â”œâ”€â”€ models.py              # Base autoencoder architectures
â”‚   â”œâ”€â”€ model_variants.py      # Lightweight, robust, high-capacity variants
â”‚   â””â”€â”€ optimization.py        # Advanced training techniques
â”‚
â”œâ”€â”€ ğŸ“Š Data & Training  
â”‚   â”œâ”€â”€ dataset.py             # Data loading and preprocessing
â”‚   â”œâ”€â”€ trainer.py             # Basic training loop
â”‚   â”œâ”€â”€ train.py              # Main training script
â”‚   â””â”€â”€ config.json           # Training configuration
â”‚
â”œâ”€â”€ ğŸ” Inference & Testing
â”‚   â”œâ”€â”€ inference.py          # Single image processing
â”‚   â”œâ”€â”€ batch_process.py      # Batch operations
â”‚   â”œâ”€â”€ evaluate.py           # Comprehensive evaluation
â”‚   â””â”€â”€ demo.py               # Interactive demonstration
â”‚
â”œâ”€â”€ ğŸŒ Web Interface
â”‚   â”œâ”€â”€ web_app.py            # Flask web application
â”‚   â”œâ”€â”€ web_config.json       # Web app configuration
â”‚   â””â”€â”€ templates/            # HTML templates
â”‚
â”œâ”€â”€ ğŸš€ Deployment
â”‚   â”œâ”€â”€ setup.py              # Automated setup script
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â”œâ”€â”€ QUICKSTART.md         # Quick start guide
â”‚   â””â”€â”€ README.md             # This comprehensive guide
â”‚
â””â”€â”€ ğŸ“‚ Generated Directories
    â”œâ”€â”€ checkpoints/          # Model checkpoints
    â”œâ”€â”€ visualizations/       # Training plots
    â”œâ”€â”€ results/             # Inference outputs
    â”œâ”€â”€ evaluation_results/   # Evaluation reports
    â”œâ”€â”€ optimized_results/    # Optimization results
    â”œâ”€â”€ web_uploads/         # Web app uploads
    â”œâ”€â”€ web_results/         # Web app outputs
    â””â”€â”€ sample_images/       # Demo images
```

## Model Architecture Details

### Encoder Network
- Input: 6-channel concatenated image (cover + secret)
- Convolutional layers with increasing channel dimensions: 64 â†’ 128 â†’ 256 â†’ 512
- Skip connections for better gradient flow
- Output: 3-channel stego image

### Decoder Network
- Input: 3-channel stego image
- Transposed convolutional layers with decreasing channel dimensions: 512 â†’ 256 â†’ 128 â†’ 64
- Skip connections for feature preservation
- Output: 3-channel recovered secret image

### Loss Function
```python
Total Loss = Î± Ã— Cover Loss + Î² Ã— Secret Loss + Î³ Ã— SSIM Loss
```
Where:
- Cover Loss: MSE between cover and stego images
- Secret Loss: MSE between original and recovered secret images
- SSIM Loss: Structural similarity for visual quality

## Training Process

1. **Data Preparation**: Images are resized to 128Ã—128 and normalized to [-1, 1]
2. **Training Loop**: 
   - Forward pass through encoder and decoder
   - Loss calculation with multiple components
   - Backward pass and optimization
   - Regular visualization and checkpointing
3. **Validation**: Regular evaluation on validation set
4. **Metrics**: PSNR and SSIM calculation for quality assessment

## Results and Metrics

The model is evaluated using:

- **PSNR (Peak Signal-to-Noise Ratio)**: Measures image quality
- **SSIM (Structural Similarity Index)**: Measures perceptual similarity
- **Cover Loss**: Ensures minimal distortion to cover image
- **Secret Loss**: Ensures accurate secret image recovery

## Example Results

After training, you should see:
- Stego images that are visually similar to cover images
- Recovered secret images with high fidelity
- PSNR values > 30 dB for good quality
- SSIM values > 0.9 for high similarity

## Customization

### Modifying Architecture

Edit `models.py` to change:
- Network depth and width
- Activation functions
- Loss function weights

### Using Different Datasets

1. **Custom Dataset**: Place images in a directory and use `--custom_image_dir`
2. **Other Datasets**: Modify `dataset.py` to support other datasets

### Hyperparameter Tuning

Key parameters to experiment with:
- Learning rate (`--lr`)
- Batch size (`--batch_size`)
- Loss weights (in `SteganographyLoss`)
- Network architecture (hidden dimensions)

## Troubleshooting

### Common Issues

1. **CUDA Out of Memory**:
   - Reduce batch size: `--batch_size 16`
   - Use CPU: `--device cpu`

2. **Slow Training**:
   - Use GPU: `--device cuda`
   - Reduce image size: `--image_size 64`

3. **Poor Results**:
   - Increase training epochs
   - Adjust learning rate
   - Check data quality

### Performance Tips

- Use GPU for faster training
- Start with CIFAR-10 for initial testing
- Monitor loss curves during training
- Use appropriate batch size for your hardware

## ğŸ¯ Advanced Features

### ğŸ—ï¸ Model Variants
- **Lightweight Models**: Optimized for mobile/edge deployment with depthwise separable convolutions
- **High-Capacity Models**: Enhanced architecture with attention mechanisms for complex images
- **Robust Models**: Noise-resistant training with dropout and augmentation for attack resilience
- **Adaptive Models**: Dynamic switching between different operating modes

### âš¡ Optimization Techniques
- **Mixed Precision Training**: Up to 2x speedup with automatic loss scaling
- **Advanced Optimizers**: AdamW with parameter group scheduling
- **Learning Rate Scheduling**: Cosine annealing and plateau reduction
- **Gradient Clipping**: Stable training with gradient norm constraints
- **Early Stopping**: Automatic training termination with patience monitoring

### ğŸ”’ Robustness Features
- **Attack Simulation**: JPEG compression, Gaussian noise, blur, rotation, scaling
- **Quality Metrics**: PSNR, SSIM, perceptual similarity measurements
- **Batch Evaluation**: Automated testing across multiple attack scenarios
- **Performance Benchmarking**: Comprehensive model comparison tools

### ğŸŒ Production Deployment
- **Web Interface**: Professional Flask application with responsive design
- **RESTful API**: Programmatic access for system integration
- **Batch Processing**: Parallel processing for high-throughput scenarios
- **Configuration Management**: JSON-based configuration for different environments

### ğŸ“Š Analysis & Monitoring
- **Training Visualization**: Real-time loss curves and metric tracking
- **Model Profiling**: Parameter counting and memory usage analysis
- **Quality Assessment**: Automated image quality evaluation
- **Performance Logging**: Comprehensive training history and checkpointing

## ğŸ”¬ Research Applications

This comprehensive implementation enables research in:

1. **Video Steganography**: Frame-by-frame processing with temporal consistency
2. **Adversarial Steganography**: Robust hiding against detection algorithms
3. **Mobile Steganography**: Lightweight models for real-time mobile applications
4. **Multi-Modal Hiding**: Embedding different types of data (text, audio, video)
5. **Adaptive Steganography**: Dynamic adjustment based on content analysis
6. **Distributed Systems**: Scalable deployment across multiple machines

## Contributing

We welcome contributions! Please see our contribution guidelines:

### Development Setup
```bash
# Clone the repository
git clone <repository-url>
cd DigitalWatermarking

# Install development dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt  # If available

# Run tests
python -m pytest tests/

# Run code quality checks
flake8 *.py
black *.py --check
```
